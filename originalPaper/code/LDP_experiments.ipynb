{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZff0VkNdGY8",
    "outputId": "64f7b3c5-95e3-44c5-c72e-683ec63ad6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/szymonr/.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Requirement already satisfied: networkx in /home/szymonr/.local/lib/python3.10/site-packages (3.1)\n",
      "Requirement already satisfied: pandas in /home/szymonr/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: statsmodels in /home/szymonr/.local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/szymonr/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/szymonr/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/lib/python3/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: filelock in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/szymonr/.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: lit in /home/szymonr/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: cmake in /home/szymonr/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/szymonr/.local/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Installing collected packages: nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed nvidia-cudnn-cu11-8.5.0.96 torch-2.0.0 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn numpy matplotlib networkx pandas scipy torch statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
      "Requirement already satisfied: pyg_lib in /home/piotr/Documents/studia/eksploracja/projekt/AGH---Data-exploration---Graph-Classification/.venv/lib/python3.10/site-packages (0.2.0+pt113cu117)\n",
      "Requirement already satisfied: torch_scatter in /home/piotr/Documents/studia/eksploracja/projekt/AGH---Data-exploration---Graph-Classification/.venv/lib/python3.10/site-packages (2.1.1+pt113cu117)\n",
      "Requirement already satisfied: torch_sparse in /home/piotr/Documents/studia/eksploracja/projekt/AGH---Data-exploration---Graph-Classification/.venv/lib/python3.10/site-packages (0.6.17+pt113cu117)\n",
      "Requirement already satisfied: scipy in /home/piotr/Documents/studia/eksploracja/projekt/AGH---Data-exploration---Graph-Classification/.venv/lib/python3.10/site-packages (from torch_sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/piotr/Documents/studia/eksploracja/projekt/AGH---Data-exploration---Graph-Classification/.venv/lib/python3.10/site-packages (from scipy->torch_sparse) (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
    "# tu trzeba wpisać odpowiednią wersję CUDA, patrz: https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from torch-geometric) (1.8.0)\n",
      "Collecting psutil>=5.8.0\n",
      "  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torch-geometric) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /home/szymonr/.local/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /home/szymonr/.local/lib/python3.10/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/szymonr/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/szymonr/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=895986 sha256=374f18a950d6f45b04b7572519b3133d73cccfe7f83f1ea5b589159bb1023344\n",
      "  Stored in directory: /home/szymonr/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: psutil, torch-geometric\n",
      "Successfully installed psutil-5.9.5 torch-geometric-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/IMDB-BINARY.zip\n",
      "Extracting ../data/IMDB-BINARY/IMDB-BINARY.zip\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/IMDB-MULTI.zip\n",
      "Extracting ../data/IMDB-MULTI/IMDB-MULTI.zip\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-BINARY.zip\n",
      "Extracting ../data/REDDIT-BINARY/REDDIT-BINARY.zip\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-MULTI-5K.zip\n",
      "Extracting ../data/REDDIT-MULTI-5K/REDDIT-MULTI-5K.zip\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-MULTI-12K.zip\n",
      "Extracting ../data/REDDIT-MULTI-12K/REDDIT-MULTI-12K.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "ROOT_DATA_PATH = \"../data\"\n",
    "\n",
    "imdb_binary_dataset = TUDataset(root=ROOT_DATA_PATH, name=\"IMDB-BINARY\")\n",
    "imdb_multi_dataset = TUDataset(root=ROOT_DATA_PATH, name=\"IMDB-MULTI\")\n",
    "reddit_binary_dataset = TUDataset(root=ROOT_DATA_PATH, name=\"REDDIT-BINARY\")\n",
    "reddit_multi_5k_dataset = TUDataset(root=ROOT_DATA_PATH, name=\"REDDIT-MULTI-5K\")\n",
    "reddit_multi_12k_dataset = TUDataset(root=ROOT_DATA_PATH, name=\"REDDIT-MULTI-12K\")\n",
    "\n",
    "# do pobrania jeszcze dataset z cząsteczkami stąd: https://ogb.stanford.edu/docs/graphprop/#pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS = {\n",
    "    'n_bin': 30,  # number of bins for historgram\n",
    "    'norm_flag': 'no',  # normalize before calling function_basis versus normalize after\n",
    "    'nonlinear_flag': 'True',  # SVM linear kernel versus nonlinear kernel\n",
    "    'uniform_flag': True,  # unform versus log scale. True for imdb, False for reddit.\n",
    "    'cdf_flag': True,  # cdf versus pdf. True for most dataset.\n",
    "    'his_norm_flag': 'yes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from dataset imdb_binary\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Number of bins are 30\n",
      "the shape after removing zero columns is  (1000, 145)\n",
      "imdb_binary\n",
      "Evaluating with SVM\n",
      "[0.77 0.73 0.75 0.78 0.69 0.69 0.67 0.76 0.74 0.69]\n",
      "[0.72 0.77 0.69 0.73 0.74 0.64 0.79 0.69 0.76 0.78]\n",
      "[0.71 0.73 0.73 0.69 0.7  0.73 0.75 0.74 0.76 0.77]\n",
      "[0.71 0.72 0.74 0.71 0.8  0.71 0.67 0.69 0.76 0.71]\n",
      "[0.71 0.75 0.78 0.73 0.77 0.71 0.7  0.7  0.69 0.73]\n",
      "[0.77 0.74 0.68 0.77 0.73 0.72 0.81 0.72 0.65 0.64]\n",
      "[0.7  0.68 0.75 0.68 0.79 0.71 0.73 0.67 0.78 0.66]\n",
      "[0.73 0.71 0.73 0.81 0.68 0.76 0.7  0.73 0.64 0.72]\n",
      "[0.74 0.79 0.66 0.76 0.69 0.74 0.77 0.76 0.7  0.67]\n",
      "[0.68 0.66 0.8  0.7  0.78 0.75 0.75 0.7  0.72 0.76]\n",
      "mean is 0.7254999999999999, std is 0.00490407993409567 \n",
      "'evaluate_svm'  7.68 s\n"
     ]
    }
   ],
   "source": [
    "from main import evaluate\n",
    "\n",
    "evaluate(dataset=\"imdb_binary\", classifier='svm', baseline='ldp', hyperparams=HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from dataset imdb_binary\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Number of bins are 30\n",
      "The max of list is 2.614135177033117\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92060/3115958820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imdb_binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ldp_extended'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/main.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, classifier, baseline, hyperparams)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph_tudataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_graphs_to_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mevaluate_with_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/main.py\u001b[0m in \u001b[0;36mconvert_graphs_to_vectors\u001b[0;34m(dataset, graphs, labels, baseline, hyperparams)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_vectors_graph_invariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ldp_extended'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_vectors_ldp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported baseline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/baselines.py\u001b[0m in \u001b[0;36mconvert_to_vectors_ldp\u001b[0;34m(dataset, graphs, labels, hyperparams, extended)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mextended_features\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextended\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     x_original = merge_features(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/tunning.py\u001b[0m in \u001b[0;36mmerge_features\u001b[0;34m(graph, graphs_, allowed, n_bin, his_norm_flag, edge_flag, cdf_flag, uniform_flag)\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/tunning.py\u001b[0m in \u001b[0;36mhisgram_single_feature\u001b[0;34m(graphs_, n_bin, key, his_norm_flag, edge_flag, lowerbound, upperbound, cdf_flag, uniform_flag)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mfeature_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         feature_vec[i] = hisgram(lis, n_bin, his_norm_flag=his_norm_flag,\n\u001b[0m\u001b[1;32m     37\u001b[0m                                  \u001b[0mlowerbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlowerbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupperbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupperbound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                  cdf_flag=cdf_flag, uniform_flag=uniform_flag)\n",
      "\u001b[0;32m~/Documents/Projekty/AGH---Data-exploration---Graph-Classification/originalPaper/code/tunning.py\u001b[0m in \u001b[0;36mhisgram\u001b[0;34m(lis, n_bin, his_norm_flag, lowerbound, upperbound, cdf_flag, uniform_flag)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mn_bin_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcdf_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical_distribution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mECDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mecdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mECDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from main import evaluate\n",
    "\n",
    "evaluate(dataset=\"imdb_binary\", classifier='svm', baseline='ldp_extended', hyperparams=HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from dataset imdb_binary\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Number of bins are 30\n",
      "the shape after removing zero columns is  (1000, 145)\n",
      "LDP x: (1000, 145), y: (1000,)\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Graph invariants x: (1000, 4), y: (1000,)\n"
     ]
    }
   ],
   "source": [
    "from graph import load_graph\n",
    "from main import convert_graphs_to_vectors\n",
    "\n",
    "dataset = 'imdb_binary'\n",
    "\n",
    "graphs, labels = load_graph(dataset)\n",
    "\n",
    "x_ldp, y_ldp = convert_graphs_to_vectors(dataset, graphs, labels, baseline='ldp', hyperparams=HYPERPARAMS)\n",
    "\n",
    "print(f\"LDP x: {x_ldp.shape}, y: {y_ldp.shape}\")\n",
    "\n",
    "x_invars, y_invars = convert_graphs_to_vectors(dataset, graphs, labels, baseline='graph_invariants', hyperparams=HYPERPARAMS)\n",
    "\n",
    "print(f\"Graph invariants x: {x_invars.shape}, y: {y_invars.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from dataset imdb_binary\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Number of bins are 30\n",
      "the shape after removing zero columns is  (1000, 145)\n",
      "Evaluating with Random Forest\n",
      "Accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "evaluate(dataset=\"imdb_binary\", classifier='random_forest', baseline='ldp', hyperparams=HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from dataset imdb_binary\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "imdb_binary\n",
      "Evaluating with SVM\n",
      "[0.64 0.61 0.61 0.61 0.69 0.64 0.67 0.64 0.65 0.64]\n",
      "[0.65 0.66 0.63 0.57 0.71 0.59 0.63 0.65 0.64 0.66]\n",
      "[0.7  0.53 0.68 0.69 0.64 0.6  0.68 0.66 0.62 0.65]\n",
      "[0.64 0.71 0.65 0.59 0.68 0.62 0.65 0.68 0.62 0.58]\n",
      "[0.69 0.66 0.65 0.66 0.7  0.66 0.59 0.61 0.6  0.63]\n",
      "[0.71 0.66 0.65 0.6  0.62 0.55 0.65 0.72 0.59 0.63]\n",
      "[0.54 0.59 0.65 0.61 0.64 0.67 0.72 0.73 0.66 0.62]\n",
      "[0.71 0.58 0.7  0.63 0.58 0.63 0.66 0.59 0.7  0.61]\n",
      "[0.66 0.67 0.55 0.67 0.63 0.6  0.73 0.57 0.66 0.69]\n",
      "[0.61 0.53 0.62 0.67 0.75 0.71 0.63 0.65 0.63 0.6 ]\n",
      "mean is 0.6414, std is 0.002416609194718913 \n",
      "'evaluate_svm'  118.57 s\n"
     ]
    }
   ],
   "source": [
    "evaluate(dataset=\"imdb_binary\", classifier='svm', baseline='graph_invariants', hyperparams=HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ GRAPH\n",
      "GRAPH READED\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "Number of bins are 30\n",
      "the shape after removing zero columns is  (1000, 145)\n",
      "Evaluating with Random Forest\n",
      "Accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "evaluate(dataset=\"IMDB-BINARY\", classifier='random_forest', baseline='ldp', hyperparams=HYPERPARAMS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
